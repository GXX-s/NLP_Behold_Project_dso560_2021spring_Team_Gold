{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore various machine learning algorithms with the input variables created in the second notebook, including Logistic Regression, Deep Learning, RNN and LSTM. For the input variables, we tried different combinations of vectorizing methods and feature encoding methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS: We are not able to have the outputs for all the models because this notebook takes long to run entirely. The teammates ran models separately on their own computer. In this submission, we will include the model performance if we cannot obtain the running output in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:31:45.913824Z",
     "start_time": "2021-05-12T05:31:43.438221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxuegu/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/xinxuegu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/xinxuegu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "import seaborn as sns\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:31:47.345701Z",
     "start_time": "2021-05-12T05:31:47.334509Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:31:47.379513Z",
     "start_time": "2021-05-12T05:31:47.358291Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:31:52.075991Z",
     "start_time": "2021-05-12T05:31:47.749864Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:31:52.096532Z",
     "start_time": "2021-05-12T05:31:52.093914Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:31:52.110789Z",
     "start_time": "2021-05-12T05:31:52.108395Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:31:52.127006Z",
     "start_time": "2021-05-12T05:31:52.124054Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T06:12:54.513079Z",
     "start_time": "2021-05-12T06:12:54.509546Z"
    }
   },
   "outputs": [],
   "source": [
    "##import Keras Toolkit\n",
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the '2_Prepare_Training_Data_behold_project.ipynb' notebook, we have created many varibles using Countvectorization, TFIDFVectorizer, Integer Encoding on our lemmatized description. Besides, we encoded the manually created features using one-hot encoding. \n",
    "\n",
    "We also conducted PCA dimensionality reduction on them. The following are our outputs:\n",
    "\n",
    "1. CountVectorized: X_cv.pkl, princ_comps_cv.pkl\n",
    "2. TfidfVectorized: X_tfidf.pkl,princ_comps_tfidf.pkl\n",
    "3. Encoded Feature: cat_feat_array.pkl,features_princ_comps.pkl\n",
    "4. Integer Encoding and Padding: padded_docs.pkl \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore what kind of input variables can bring better performance to our machine learning models, we concatenate the data above to create different combinations of training data.\n",
    "We saved those variables as Pickle files for quicker loading speed. \n",
    "\n",
    "1.the countvectorized lemma description + encoded feature array with PCA\n",
    "    \n",
    "    cv_featPca_1.pkl\n",
    "\n",
    "2.the countvectorized lemma description with PCA + encoded feature vector without PCA\n",
    "\n",
    "    cvPca_feat_2.pkl: \n",
    "3.the the countvectorized lemma description with PCA + encoded feature array with PCA\n",
    "    \n",
    "    cvPca_featPca_3.pkl\n",
    "    \n",
    "4.the tfidf vectorized lemma description with PCA + encoded feature array with PCA\n",
    "    \n",
    "    tfidfPca_featPca_4.pkl\n",
    "\n",
    "\n",
    "5.For the deep learning models we prepared a tokenized lemmatized description using keras.preprocessing.text.Tokenizer, and saved in the following file:\n",
    "    \n",
    "    tokenizer_word_index.pkl\n",
    "\n",
    "6.We also saved the pretrained GloVe Embeddings as pkl file so that we can load it faster. \n",
    "    \n",
    "    embedding_matrix.pkl\n",
    "\n",
    "\n",
    "The cells below are to load these variables into the environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS: If you don't have the pkl files below in your local environment, just run the second notebook thoroughly from the beginning, then you will have them all. It only takes less than 10 mins to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:31:55.814158Z",
     "start_time": "2021-05-12T05:31:54.965458Z"
    }
   },
   "outputs": [],
   "source": [
    "# final cleaned data \n",
    "with open('final_cleaned_data.pkl', 'rb') as f:\n",
    "    behold_prod = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:31:59.747772Z",
     "start_time": "2021-05-12T05:31:56.416689Z"
    }
   },
   "outputs": [],
   "source": [
    "# # load variables with this chunk of code\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Encode Features\n",
    "# cat_feat_array.pkl is the array of encoded features\n",
    "with open('cat_feat_array.pkl', 'rb') as f:\n",
    "        cat_feat_array = pickle.load(f)\n",
    "\n",
    "# features_princ_comps.pkl is pca on the encoded feature array (cat_feat_array.pkl)\n",
    "with open('features_princ_comps.pkl', 'rb') as f:\n",
    "     features_princ_comps = pickle.load(f)\n",
    "\n",
    "#=====================================================================   \n",
    "#Countvectorizer\n",
    "# X_cv.pkl is the Countvertorized lemmatized descriptions\n",
    "with open('X_cv.pkl', 'rb') as f:\n",
    "    X_cv = pickle.load(f)\n",
    "# princ_comps_cv.pkl is the pca on Countvertorized lemmatized descriptions(X_cv.pkl)\n",
    "with open('princ_comps_cv.pkl', 'rb') as f:\n",
    "    princ_comps_cv = pickle.load(f)\n",
    "\n",
    "#=====================================================================   \n",
    "#TFIDF\n",
    " # X_tfidf.pkl is the tfidf vectorized lemmatized description\n",
    "with open('X_tfidf.pkl', 'rb') as f:\n",
    "    X_tfidf = pickle.load(f)\n",
    " # princ_comps_tfidf.pkl is the tfidf vectorized lemmatized description(X_tfidf.pkl) with PCA\n",
    "with open('princ_comps_tfidf.pkl', 'rb') as f:\n",
    "    princ_comps_tfidf = pickle.load(f)\n",
    "\n",
    "#=====================================================================  \n",
    "\n",
    "## combinations of the above data, to make different set of training data\n",
    "## the number in the file name indicates their order to be used in the model exploration\n",
    "## they were named X_all before\n",
    "\n",
    "# cv_featPca_1.pkl is the countvectorized lemma description + encoded feature array with PCA\n",
    "with open('cv_featPca_1.pkl', 'rb') as f:\n",
    "    cv_featPca_1 = pickle.load(f)\n",
    "# cvPca_feat_2.pkl is the countvectorized lemma description with PCA + encoded feature vector without PCA\n",
    "with open('cvPca_feat_2.pkl', 'rb') as f:\n",
    "    cvPca_feat_2 = pickle.load(f)    \n",
    "# cvPca_featPca_3.pkl is the the countvectorized lemma description with PCA + encoded feature array with PCA\n",
    "with open('cvPca_featPca_3.pkl', 'rb') as f:\n",
    "    cvPca_featPca_3 = pickle.load(f)  \n",
    "# tfidfPca_featPca_4.pkl is the tfidf vectorized lemma description with PCA + encoded feature array with PCA\n",
    "with open('tfidfPca_featPca_4.pkl', 'rb') as f:\n",
    "     tfidfPca_featPca_4 = pickle.load(f)  \n",
    "\n",
    "#===================================================================== \n",
    "#tokenizer_word_index.pkl is the tokenized lemma description \n",
    "with open('tokenizer_word_index.pkl', 'rb') as f:\n",
    "    tokenizer_word_index =  pickle.load(f)   \n",
    "# padded_docs.pkl is the lemmatized_description after integer encoding and padding \n",
    "with open('padded_docs.pkl', 'rb') as f:\n",
    "    padded_docs = pickle.load(f) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:32:00.098621Z",
     "start_time": "2021-05-12T05:32:00.069757Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# embedding_matrix.pkl is the loaded pretrained embeddings from GloVe\n",
    "with open('embedding_matrix.pkl', 'rb') as f:\n",
    "    embedding_matrix = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:32:00.366960Z",
     "start_time": "2021-05-12T05:32:00.364240Z"
    }
   },
   "outputs": [],
   "source": [
    "## define dependent variable\n",
    "labels = behold_prod['label']\n",
    "\n",
    "corpus = behold_prod['lemmatized_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of labels we need to classify is 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:32:02.148719Z",
     "start_time": "2021-05-12T05:32:02.137139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(behold_prod.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding the Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current brand labels are strings. We need to use LabelEncoder to transform them into numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T04:30:35.150363Z",
     "start_time": "2021-05-12T04:30:35.103172Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(behold_prod['label'].astype(str))\n",
    "y=le.transform(behold_prod['label'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models explored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried logistic regression algorithm on the vectorized lemmtized description with different vectorizing method (countvectorize, tfidf), and run them with or without encoded features. \n",
    "\n",
    "The best performance is from LR on CountVectorisation(no PCA) + Encoded Features (PCA), which has around 90% accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:34:54.928962Z",
     "start_time": "2021-05-11T12:34:54.921712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fix number of iterations\n",
    "iteration_count=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR on CountVectorisation(without PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we run a LR model on the count vectorized lemma description, without PCA, without adding encoded features. The accuracy is around 88%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:37:35.917672Z",
     "start_time": "2021-05-11T12:37:35.907459Z"
    }
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:38:51.756691Z",
     "start_time": "2021-05-11T12:38:14.278642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8828131366636786\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,iteration_count):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_cv,y, test_size=0.2, random_state=n,stratify=y)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    print(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR on CountVectorisation(with PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the same model with principle components. The accuracy drops a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8642327438676555\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,iteration_count):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(princ_comps_cv ,y, test_size=0.2, random_state=n,stratify=y)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    print(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR on CountVectorisation(non PCA) + Encoded Features (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we added encoded features' PCA to the input variables. The accuracy improved from 88% to nearly 90%. This means our encoded features are useful in terms of predicting brands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:39:08.165619Z",
     "start_time": "2021-05-11T12:39:08.163427Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_all=np.concatenate([X_cv.toarray(),features_princ_comps],axis=1)\n",
    "X_all = cv_featPca_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:39:18.367657Z",
     "start_time": "2021-05-11T12:39:18.363412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61355, 2743)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:40:20.309850Z",
     "start_time": "2021-05-11T12:39:19.828897Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9054681770026892\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,1):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_all ,y, test_size=0.2, random_state=n,stratify=y)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    print(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR on CountVectorisation(PCA) + Encoded Features (non PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another LR model runs on conunvectors' pca and encoded features without pca. The performance drops a little but is still better than the model without encoded features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:40:27.732325Z",
     "start_time": "2021-05-11T12:40:27.727870Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_all=np.concatenate([princ_comps_cv,cat_feat_array],axis=1)\n",
    "X_all = cvPca_feat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:40:40.910924Z",
     "start_time": "2021-05-11T12:40:40.905195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61355, 550)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:43:56.437452Z",
     "start_time": "2021-05-11T12:40:51.216675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8871322630592454\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,1):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_all ,y, test_size=0.2, random_state=n,stratify=y)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    print(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR on CountVectorisation(PCA) + Encoded Features (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model runs on conunvectors' pca and encoded features pca. This performed slightly worse than the countvectorisation(no pca) + encoded features (PCA). But considering the input variables for this has lower dimensions, we will use this one as our baseline for reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:45:36.154537Z",
     "start_time": "2021-05-11T12:45:36.150936Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_all=np.concatenate([princ_comps_cv,features_princ_comps],axis=1)\n",
    "X_all = cvPca_featPca_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:45:37.856375Z",
     "start_time": "2021-05-11T12:45:37.850963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61355, 520)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:47:43.101894Z",
     "start_time": "2021-05-11T12:46:22.024349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8942221497840437\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,1):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_all ,y, test_size=0.2, random_state=n,stratify=y)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    print(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR on TF-IDF(with PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the Countvectorizer, we use TFIDF to vectorize the lemma descriptions. As you can see the performance is not as good as the ones using Countvectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7543802461087116\n",
      "0.7544617390595714\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,2):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(princ_comps_tfidf ,y, test_size=0.2, random_state=n,stratify=y)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    print(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR on TF-IDF+Encoded Features (both PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses TFIDF vectorized lemma descriptions with pca plus the encoded features with pca. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:43:57.335901Z",
     "start_time": "2021-05-11T12:43:57.331615Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_all=np.concatenate([princ_comps_tfidf,features_princ_comps],axis=1)\n",
    "X_all = tfidfPca_featPca_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7956971721946051\n",
      "0.8015646646565072\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,2):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_all ,y, test_size=0.2, random_state=n,stratify=y)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    print(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used keras library to run the deep learning model. We tried running with or without pretrained embeddings (GloVe), with or without encoded features.\n",
    "\n",
    "For all the deep learning models, we don't have the running outputs in this notebook. Because they were run on another computer. But the model performances were documented below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T04:30:49.771471Z",
     "start_time": "2021-05-12T04:30:49.751715Z"
    }
   },
   "outputs": [],
   "source": [
    "## label the dependent variable\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "labels=behold_prod['label']\n",
    "labels = to_categorical(encoder.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input varibles are from the padded_docs created in the second notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T04:30:52.016532Z",
     "start_time": "2021-05-12T04:30:51.893117Z"
    }
   },
   "outputs": [],
   "source": [
    "## split train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Pretrained Embeddings + Without encoded Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build a model without pretrained embbeddings (weights), just let the algorithm to decide. This is the baseline for deep learning models. \n",
    "\n",
    "The accuacy is around 82%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the max_length to be 300. The embedding shape will be (300,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:35:15.749502Z",
     "start_time": "2021-05-12T05:35:15.745972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is 45548 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "max_length=300\n",
    "vocab_size = int(len(tokenizer_word_index) * 1.3)\n",
    "print(f\"Vocab size is {vocab_size} unique tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T04:31:00.770317Z",
     "start_time": "2021-05-12T04:31:00.481711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 300)          13664400  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 90000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 31)                2790031   \n",
      "=================================================================\n",
      "Total params: 16,454,431\n",
      "Trainable params: 16,454,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(31, activation='softmax')) \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-12T04:31:03.408Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=30, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### With Pretrained Embeddings + Without encoded Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second deep learning model we tried uses the GloVe embeddings only, without adding and encoded features. \n",
    "\n",
    "The model accuracy is around 84%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T14:34:50.051714Z",
     "start_time": "2021-05-11T14:34:49.906342Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100,weights=[embedding_matrix], input_length=300, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(31, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T14:37:47.628727Z",
     "start_time": "2021-05-11T14:34:54.130132Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=30, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Pretrained Embeddings + Encoded Features as an additional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also tried adding encoded features as an additional layer on top of the pretrained embeddings. \n",
    "\n",
    "But the performance is as good as the other ones. It only has less than 80% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T14:38:11.446205Z",
     "start_time": "2021-05-11T14:38:11.442093Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = int(len(tokenizer_word_index) * 1.3)\n",
    "print(f\"Vocab size is {vocab_size} unique tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T14:38:12.648483Z",
     "start_time": "2021-05-11T14:38:12.645800Z"
    }
   },
   "outputs": [],
   "source": [
    "length_cat_array=cat_feat_array.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T14:38:13.927412Z",
     "start_time": "2021-05-11T14:38:13.921705Z"
    }
   },
   "outputs": [],
   "source": [
    "length_cat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T14:38:16.735516Z",
     "start_time": "2021-05-11T14:38:16.532404Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "model=Sequential()\n",
    "# Use Input layers, specify input shape (dimensions except first)\n",
    "inp_text_data = keras.layers.Input(shape=(300,))\n",
    "inp_cat_data = keras.layers.Input(shape=(length_cat_array))\n",
    "# Bind nulti_hot to embedding layer\n",
    "emb = keras.layers.Embedding(vocab_size,input_length=300,weights=[embedding_matrix], output_dim=100,trainable=False)(inp_text_data)  \n",
    "# Also you need flatten embedded output of shape (?,3,2) to (?, 6) -\n",
    "# otherwise it's not possible to concatenate it with inp_num_data\n",
    "flatten = keras.layers.Flatten()(emb)\n",
    "# Concatenate two layers\n",
    "conc = keras.layers.Concatenate()([flatten, inp_cat_data])\n",
    "# dense1 = keras.layers.Dense(31)(conc)\n",
    "# Creating output layer\n",
    "out = keras.layers.Dense(31, activation='softmax')(conc)\n",
    "model = keras.Model(inputs=[inp_text_data, inp_cat_data], outputs=out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN is good at processing sequence data for prediction. Text can also be sequence data. We fit the RNN model with pre-trained embeddings on the lemmatized description corpus. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Embedding + RNN (no pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we use the glove embeddings. The input variables are just the lemmatized desciption in the behold_prod dataframe. The accuracy is around 80%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T13:17:28.675653Z",
     "start_time": "2021-05-11T13:17:23.162691Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:34:29.660352Z",
     "start_time": "2021-05-12T05:34:29.657872Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = behold_prod['lemmatized_description']\n",
    "labels = behold_prod['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:34:33.630384Z",
     "start_time": "2021-05-12T05:34:31.511035Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## tokenize text\n",
    "\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# # so this means that all tokens that are not found in the vocabulary are going to be marked as UNKNOWN_TOKEN\n",
    "# tokenizer = Tokenizer(num_words=10000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "# tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the tokenized word from the second notebook: tokenizer_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = int(len(tokenizer_word_index) * 1.3)\n",
    "print(f\"Vocab size is {vocab_size} unique tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new padded docs here to provide some flexibility for model adjusting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:34:36.384989Z",
     "start_time": "2021-05-12T05:34:34.967447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66, 39, 8, 7, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "# integer encode the documents\n",
    "encoded_docs = integer_encode_documents(corpus, tokenizer)\n",
    "# see some lengths of the documents\n",
    "list(map(len, encoded_docs))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:34:37.707237Z",
     "start_time": "2021-05-12T05:34:37.699012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(map(len, encoded_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding the encoded docs with length equals to the maximum length of encoded docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:34:39.231743Z",
     "start_time": "2021-05-12T05:34:39.229376Z"
    }
   },
   "outputs": [],
   "source": [
    "# set MAX_SEQUENCE_LENGTH \n",
    "MAX_SEQUENCE_LENGTH = 513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:34:41.332236Z",
     "start_time": "2021-05-12T05:34:40.879065Z"
    }
   },
   "outputs": [],
   "source": [
    "padded_docs = pad_sequences(encoded_docs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:34:42.636432Z",
     "start_time": "2021-05-12T05:34:42.619747Z"
    }
   },
   "outputs": [],
   "source": [
    "## encode the label\n",
    "encoder = LabelEncoder()\n",
    "labels = to_categorical(encoder.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:34:45.600959Z",
     "start_time": "2021-05-12T05:34:45.504437Z"
    }
   },
   "outputs": [],
   "source": [
    "## split train and test\n",
    "## independent variables using the new padded docs we just created \n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:34:49.066545Z",
     "start_time": "2021-05-12T05:34:49.063536Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model \n",
    "import keras\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from keras.layers import Flatten, Masking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:36:09.468134Z",
     "start_time": "2021-05-12T05:36:09.461835Z"
    }
   },
   "outputs": [],
   "source": [
    "## define the rnn model \n",
    "def make_classification_rnn_model(plot=False):\n",
    "    model =  keras.models.Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(SimpleRNN(units=128, input_shape=(1, MAX_SEQUENCE_LENGTH)))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(31, activation='softmax')) ## if multiple class, better use softmax rather than sigmoid\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:36:11.439985Z",
     "start_time": "2021-05-12T05:36:11.237462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 513, 100)          4554800   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 513, 100)          0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               29312     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 31)                2015      \n",
      "=================================================================\n",
      "Total params: 4,594,383\n",
      "Trainable params: 39,583\n",
      "Non-trainable params: 4,554,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## compile the model\n",
    "model = make_classification_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T05:36:21.818867Z",
     "start_time": "2021-05-12T05:36:21.814981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42948, 31)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T06:12:52.754282Z",
     "start_time": "2021-05-12T05:36:23.964913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "604/604 [==============================] - 114s 188ms/step - loss: 1.8045 - accuracy: 0.5421 - val_loss: 1.0554 - val_accuracy: 0.7185\n",
      "Epoch 2/20\n",
      "604/604 [==============================] - 120s 198ms/step - loss: 0.9715 - accuracy: 0.7393 - val_loss: 0.8979 - val_accuracy: 0.7618\n",
      "Epoch 3/20\n",
      "604/604 [==============================] - 110s 182ms/step - loss: 0.8000 - accuracy: 0.7842 - val_loss: 0.8203 - val_accuracy: 0.7814\n",
      "Epoch 4/20\n",
      "604/604 [==============================] - 109s 180ms/step - loss: 0.7396 - accuracy: 0.8002 - val_loss: 0.8405 - val_accuracy: 0.7739\n",
      "Epoch 5/20\n",
      "604/604 [==============================] - 116s 191ms/step - loss: 0.6614 - accuracy: 0.8186 - val_loss: 0.7744 - val_accuracy: 0.7972\n",
      "Epoch 6/20\n",
      "604/604 [==============================] - 106s 176ms/step - loss: 0.6168 - accuracy: 0.8324 - val_loss: 0.7940 - val_accuracy: 0.7965\n",
      "Epoch 7/20\n",
      "604/604 [==============================] - 105s 174ms/step - loss: 0.5760 - accuracy: 0.8432 - val_loss: 0.7631 - val_accuracy: 0.7998\n",
      "Epoch 8/20\n",
      "604/604 [==============================] - 101s 167ms/step - loss: 0.5366 - accuracy: 0.8530 - val_loss: 0.7708 - val_accuracy: 0.7963\n",
      "Epoch 9/20\n",
      "604/604 [==============================] - 110s 182ms/step - loss: 0.5204 - accuracy: 0.8550 - val_loss: 0.7762 - val_accuracy: 0.8033\n",
      "Epoch 10/20\n",
      "604/604 [==============================] - 101s 168ms/step - loss: 0.5205 - accuracy: 0.8559 - val_loss: 0.7964 - val_accuracy: 0.7974\n",
      "Epoch 11/20\n",
      "604/604 [==============================] - 109s 180ms/step - loss: 0.4867 - accuracy: 0.8684 - val_loss: 0.7811 - val_accuracy: 0.8044\n",
      "Epoch 12/20\n",
      "604/604 [==============================] - 115s 190ms/step - loss: 0.4764 - accuracy: 0.8690 - val_loss: 0.7865 - val_accuracy: 0.8044\n",
      "Epoch 13/20\n",
      "604/604 [==============================] - 111s 184ms/step - loss: 0.4576 - accuracy: 0.8734 - val_loss: 0.7706 - val_accuracy: 0.8063\n",
      "Epoch 14/20\n",
      "604/604 [==============================] - 112s 185ms/step - loss: 0.4342 - accuracy: 0.8785 - val_loss: 0.7527 - val_accuracy: 0.8133\n",
      "Epoch 15/20\n",
      "604/604 [==============================] - 115s 190ms/step - loss: 0.4336 - accuracy: 0.8817 - val_loss: 0.7719 - val_accuracy: 0.8142\n",
      "Epoch 16/20\n",
      "604/604 [==============================] - 114s 189ms/step - loss: 0.4296 - accuracy: 0.8829 - val_loss: 0.8581 - val_accuracy: 0.8026\n",
      "Epoch 17/20\n",
      "604/604 [==============================] - 109s 181ms/step - loss: 0.4174 - accuracy: 0.8852 - val_loss: 0.8209 - val_accuracy: 0.8056\n",
      "Epoch 18/20\n",
      "604/604 [==============================] - 108s 178ms/step - loss: 0.4208 - accuracy: 0.8842 - val_loss: 0.7889 - val_accuracy: 0.8165\n",
      "Epoch 19/20\n",
      "604/604 [==============================] - 103s 171ms/step - loss: 0.3929 - accuracy: 0.8919 - val_loss: 0.8063 - val_accuracy: 0.8114\n",
      "Epoch 20/20\n",
      "604/604 [==============================] - 101s 168ms/step - loss: 0.4083 - accuracy: 0.8893 - val_loss: 0.8469 - val_accuracy: 0.8005\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(X_train, y_train, validation_split = 0.1, \n",
    "                    epochs=20, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T06:13:27.481183Z",
     "start_time": "2021-05-12T06:13:27.280930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_fit_history(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "plot_fit_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T06:13:50.327085Z",
     "start_time": "2021-05-12T06:13:30.721640Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 20s 34ms/step - loss: 0.8141 - accuracy: 0.8095\n",
      "Accuracy: 80.952901\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Embeddings + LSTM (no pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM stands for long short term memory. They are extremely powerful time-series models. They can predict an arbitrary number of steps into the future. An LSTM module (or cell) has 5 essential components which allows it to model both long-term and short-term data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cell state (ct) - This represents the internal memory of the cell which stores both short term memory and long-term memories\n",
    "- Hidden state (ht) - This is output state information calculated w.r.t. current input, previous hidden state and current cell input which you eventually use to predict the future stock market prices. Additionally, the hidden state can decide to only retrive the short or - long-term or both types of memory stored in the cell state to make the next prediction.\n",
    "- Input gate (it) - Decides how much information from current input flows to the cell state\n",
    "- Forget gate (ft) - Decides how much information from the current input and the previous cell state flows into the current cell state\n",
    "- Output gate (ot) - Decides how much information from the current cell state flows into the hidden state, so that if needed LSTM can only pick the long-term memories or short-term memories and long-term memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:59:03.812609Z",
     "start_time": "2021-05-11T15:59:03.808927Z"
    }
   },
   "source": [
    "We tried to run LSTM with pretrained embeddings on lemmatized description corpus. The accuracy is around 89%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T06:14:19.377644Z",
     "start_time": "2021-05-12T06:14:19.374582Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from keras.layers import Flatten, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T06:14:41.581436Z",
     "start_time": "2021-05-12T06:14:41.576001Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_lstm_classification_model(plot=False):\n",
    "    model =  keras.models.Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(LSTM(units=128, input_shape=(1, MAX_SEQUENCE_LENGTH)))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(31, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting the model, we set the epochs to 10 and batch_size to 64 save some running time. But ideally if we more computing power, we can make 20 or more epochs. This may lead to better accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-12T06:14:43.384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 513, 100)          4554800   \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 513, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 31)                2015      \n",
      "=================================================================\n",
      "Total params: 4,682,319\n",
      "Trainable params: 127,519\n",
      "Non-trainable params: 4,554,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "604/604 [==============================] - 274s 448ms/step - loss: 1.8088 - accuracy: 0.5343 - val_loss: 0.7888 - val_accuracy: 0.7872\n",
      "Epoch 2/10\n",
      "604/604 [==============================] - 273s 453ms/step - loss: 0.6725 - accuracy: 0.8180 - val_loss: 0.6248 - val_accuracy: 0.8289\n",
      "Epoch 3/10\n",
      "604/604 [==============================] - 280s 463ms/step - loss: 0.5308 - accuracy: 0.8604 - val_loss: 0.5564 - val_accuracy: 0.8533\n",
      "Epoch 4/10\n",
      "604/604 [==============================] - 278s 461ms/step - loss: 0.4427 - accuracy: 0.8810 - val_loss: 0.5295 - val_accuracy: 0.8584\n",
      "Epoch 5/10\n",
      "604/604 [==============================] - 281s 465ms/step - loss: 0.4016 - accuracy: 0.8919 - val_loss: 0.5075 - val_accuracy: 0.8687\n",
      "Epoch 6/10\n",
      "604/604 [==============================] - 279s 462ms/step - loss: 0.3672 - accuracy: 0.9039 - val_loss: 0.4867 - val_accuracy: 0.8736\n",
      "Epoch 7/10\n",
      "604/604 [==============================] - 279s 462ms/step - loss: 0.3318 - accuracy: 0.9116 - val_loss: 0.4810 - val_accuracy: 0.8785\n",
      "Epoch 8/10\n",
      "604/604 [==============================] - 275s 455ms/step - loss: 0.3267 - accuracy: 0.9143 - val_loss: 0.4944 - val_accuracy: 0.8738\n",
      "Epoch 9/10\n",
      " 44/604 [=>............................] - ETA: 3:57 - loss: 0.3283 - accuracy: 0.9093"
     ]
    }
   ],
   "source": [
    "## cimpile the model\n",
    "model = make_lstm_classification_model()\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train,validation_split = 0.1, epochs=10, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T13:53:59.552733Z",
     "start_time": "2021-05-11T13:53:42.701Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_fit_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T13:53:59.558478Z",
     "start_time": "2021-05-11T13:53:43.251Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "271.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "552px",
    "left": "803px",
    "right": "20px",
    "top": "124px",
    "width": "487px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
