{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5b71a23",
   "metadata": {},
   "source": [
    "# Outfit Recommendation System (Part 2)\n",
    "\n",
    "\n",
    "For Part-B, our objective was to create a recommender algorithm to recommend an outfit given a customer’s search query. In order to implement this, we created a funnel through which the user’s query gets passed. \n",
    "\n",
    "At each stage, based on cosine similarity and a rule-based heuristic to catch edge cases, we build a recommender function to produce a complete outfit comprising of atleast 3 categories out of top, bottom, one-piece, shoe and accessories. \n",
    "\n",
    "**Steps to get a recommendation:**\n",
    "    \n",
    "    Step 1: Run the sections from Loading Stage to the Main Function (3.2)\n",
    "    Step 2: Call the outfit( ) function on the new query. This will produce an \n",
    "    outfit recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcd21f",
   "metadata": {},
   "source": [
    "## Importing Packages and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a993b21f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:21:57.891446Z",
     "start_time": "2021-05-12T00:21:43.611244Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sneharaj/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sneharaj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "from fuzzywuzzy import fuzz\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498220ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:22:32.930452Z",
     "start_time": "2021-05-12T00:21:57.897297Z"
    }
   },
   "outputs": [],
   "source": [
    "product=pd.read_excel('Behold+product+data+04262021.XLSX')\n",
    "combo=pd.read_csv('outfit_combinations USC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8c621",
   "metadata": {},
   "source": [
    "## Text Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d02524",
   "metadata": {},
   "source": [
    "This section utilizes regex and pandas to clean and prepare the data. The goal of this step is to set the stage for our outfit recommendation script. Please note that some of the preprocessing phases we included below didn't get utilized in our final function - we left it in our notebook for exploration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3f3e1",
   "metadata": {},
   "source": [
    "### Data type and text case cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01927c33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:22:33.040362Z",
     "start_time": "2021-05-12T00:22:32.934691Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datatype and case check\n",
    "combo['brand']=combo['brand'].apply(lambda x: x.lower())\n",
    "combo['product_full_name']=combo['product_full_name'].apply(lambda x: x.lower())\n",
    "product['brand']=product['brand'].astype(str)\n",
    "product['brand_name']=product['brand_name'].astype(str)\n",
    "product['brand']=product['brand'].apply(lambda x: x.lower())\n",
    "product['brand_name']=product['brand_name'].apply(lambda x: x.lower())\n",
    "stopwords=list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a35d24",
   "metadata": {},
   "source": [
    "### Regex cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788a9cf",
   "metadata": {},
   "source": [
    "#### Replacing html characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9317cf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:22:34.878290Z",
     "start_time": "2021-05-12T00:22:33.044260Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for html and other processing tags\n",
    "product.fillna('None',inplace=True)\n",
    "product.description=product.description.str.replace('\\n',' ')\n",
    "product.description=product.description.str.replace('\\r',' ')\n",
    "product.description=product.description.str.replace(r'[^\\w\\s]|_',' ')\n",
    "product.description=product.description.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92165d4a",
   "metadata": {},
   "source": [
    "#### Processing cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04524609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:22:37.945714Z",
     "start_time": "2021-05-12T00:22:34.881744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Capturing different versions of cities\n",
    "product['description']=product['description'].str.\\\n",
    "                                replace(r'\\bnew\\b\\s\\byork\\b\\s(?:\\bcity\\b)?','new_york_city ')\n",
    "product['description']=product['description'].str.\\\n",
    "                                replace(r'\\b(?:the\\s)?usa?\\b','USA')\n",
    "product['description']=product['description'].str.\\\n",
    "                                replace(r'\\b(?:the\\s)?united\\sstates\\b','USA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d07a44",
   "metadata": {},
   "source": [
    "#### Processing product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0768ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:22:59.413219Z",
     "start_time": "2021-05-12T00:22:37.956590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Capturing category\n",
    "bottom_seq=r'\\b(capri?|leggings?|bottoms?|skirts?|sweatpants?|pants?|jeans?|midi|trousers?|shorts|trunks?)\\b'\n",
    "one_piece_seq=r'\\b(kimono|jumpsuit|dress(?:es)?|gowns?|swimsuit?|onesies?|unitards?|bodysuits?|rompers?|one ?piece)\\b'\n",
    "shoe_seq=r'\\b(shoes?|sneakers?|flats|boot|heels?|sandals?|mules?|loafers?|pumps?)\\b'\n",
    "top=r'\\b(Tank|caftan|hoodies?|tshirts?|tees?|tops?|top|blouses?|jackets?|blazers?|shirts?|tops?|coats?|suits|sweaters?|sweatshirts?)\\b'\n",
    "acc=r'\\b(capes?|socks?|earrings?|belts?|gloves?|headbands?|ties?|hats?|caps?|bags?|handbags?|clutch(?:es)?|wallets?|purses?|duffels?scar(?:f|ves)?|wraps?|stoles?|shawl)\\b'\n",
    "linen=r'\\b(linens?)\\b'\n",
    "lingerie=r'\\b(bras?)\\b'\n",
    "\n",
    "dict_seq={'one_piece':one_piece_seq,\n",
    "          'shoe':shoe_seq,\n",
    "          'top':top,'acc':acc,'linen':linen,\n",
    "          'bottom':bottom_seq,'lingerie':lingerie}\n",
    "\n",
    "# Category flag\n",
    "for d in dict_seq:\n",
    "    product[f'{d}_check']=0\n",
    "    for col in ['name','description','details','brand_category']:\n",
    "        product[f'{d}_check']=product[f'{d}_check']+product[col].str.contains(dict_seq[d],case=False)\n",
    "         \n",
    "product['max_value_cat']=product[[\"bottom_check\",\"shoe_check\",\"one_piece_check\",'acc_check','top_check','linen_check','lingerie_check']].max(axis=1)\n",
    "\n",
    "# Function to identify most common category\n",
    "def max_presence(row):\n",
    "    for d in dict_seq.keys():\n",
    "        colname=f'{d}_check'\n",
    "        if (row['max_value_cat']==row[colname])&(row['max_value_cat']!=0):\n",
    "            return d\n",
    "        elif row['max_value_cat']==0:\n",
    "            return 'None'\n",
    "    \n",
    "product['final_category']=product.apply(max_presence,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a134121",
   "metadata": {},
   "source": [
    "#### Processing colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136b5a29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:10.638225Z",
     "start_time": "2021-05-12T00:22:59.419034Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61355/61355 [00:03<00:00, 19428.43it/s]\n"
     ]
    }
   ],
   "source": [
    "def findColors(txt):\n",
    "    \"\"\" Function to determine the color of item \"\"\"\n",
    "    colors_re=r'\\b(beige|light brown|black|blue ?green|blue|brown|umber|burgundy|gold(?:en)?|gray|grey|green|navy|neutral|orange|aurantia|pink|purple|violet|red|scarlet|silver|teal|white|yellow|(?:multi(?:ple)?|several|different|many|more than one) ?colou?rs?)\\b'\n",
    "    val=[]\n",
    "    txt=str(txt)\n",
    "    if re.findall(colors_re,txt,re.IGNORECASE):\n",
    "        val=re.findall(colors_re,txt,re.IGNORECASE)\n",
    "    return val\n",
    "\n",
    "product['color_list']=product['description'].apply(findColors)+product['name'].apply(findColors)\n",
    "product['colors']=product['color_list'].apply(lambda x: set(y.lower() for y in x))\n",
    "\n",
    "product['n_colors']=product['colors'].apply(len)\n",
    "product['final_color']=np.nan\n",
    "product.loc[product['n_colors']>1,'final_color']='multi'\n",
    "product.loc[product['n_colors']==1,'final_color']=product.loc[product['n_colors']==1,'colors'].\\\n",
    "                                                                        apply(lambda x:list(x)[0])\n",
    "\n",
    "# Products with multiple colors\n",
    "multi_pattern=r'\\b(?:multi(?:ple)?|several|different|many|more than one\\b)\\s? ?colou?rs?'\n",
    "for i in tqdm(range(len(product))):\n",
    "    match=re.search(multi_pattern,\n",
    "                       str(product.loc[i,'final_color']))\n",
    "    if match:\n",
    "        product.loc[i,'final_color']='multi'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b41e5",
   "metadata": {},
   "source": [
    "#### Combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ac4aba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:11.577076Z",
     "start_time": "2021-05-12T00:23:10.746583Z"
    }
   },
   "outputs": [],
   "source": [
    "# We consider only the top 30 brands within the scope of this project\n",
    "topbrands=product['brand'].value_counts()[:30].index.tolist()\n",
    "product=product[product['brand'].isin(topbrands)]\n",
    "\n",
    "# Dealing with null values\n",
    "product=product[product['brand_name'].notnull()]\n",
    "product=product[product['final_category'].notnull()]\n",
    "product=product[product['final_color'].notnull()]\n",
    "product.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7f71b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:11.672309Z",
     "start_time": "2021-05-12T00:23:11.580898Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenating columns\n",
    "combo['new_brand_product']=combo['brand'].astype(str)+' '+combo['product_full_name'].astype(str)\n",
    "product['new_brand_product']=product['brand'].astype(str)+' '+product['final_color'].astype(str)+' '+product['brand_name'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b396ba0f",
   "metadata": {},
   "source": [
    "**In summary:**\n",
    "\n",
    "> _The combo dataset corpus for TFIDF includes the concatenation of the \"brand\" column and \"product_full_name\" column._\n",
    "\n",
    "> _The product dataset corpus for TFIDF includes the concatenation of the \"brand\" column, \"brand_name\" column, and \"final_color\" column._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54044aee",
   "metadata": {},
   "source": [
    "##### A quick peek into the final processed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847fd2b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:11.964915Z",
     "start_time": "2021-05-12T00:23:11.695513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outfit_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_item_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>new_brand_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA2P5H24WK0HTK4R0A1</td>\n",
       "      <td>bottom</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>slim knit skirt</td>\n",
       "      <td>eileen fisher slim knit skirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA2PEPWFTT7RMP5AA1T</td>\n",
       "      <td>top</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>rib mock neck tank</td>\n",
       "      <td>eileen fisher rib mock neck tank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    outfit_id                  product_id outfit_item_type  \\\n",
       "0  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA2P5H24WK0HTK4R0A1           bottom   \n",
       "1  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA2PEPWFTT7RMP5AA1T              top   \n",
       "\n",
       "           brand   product_full_name                 new_brand_product  \n",
       "0  eileen fisher     slim knit skirt     eileen fisher slim knit skirt  \n",
       "1  eileen fisher  rib mock neck tank  eileen fisher rib mock neck tank  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635750fe",
   "metadata": {},
   "source": [
    "Below is the final product dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "704f5b6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:12.216189Z",
     "start_time": "2021-05-12T00:23:11.977113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>name</th>\n",
       "      <th>details</th>\n",
       "      <th>created_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_description</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>...</th>\n",
       "      <th>linen_check</th>\n",
       "      <th>bottom_check</th>\n",
       "      <th>lingerie_check</th>\n",
       "      <th>max_value_cat</th>\n",
       "      <th>final_category</th>\n",
       "      <th>color_list</th>\n",
       "      <th>colors</th>\n",
       "      <th>n_colors</th>\n",
       "      <th>final_color</th>\n",
       "      <th>new_brand_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01F0C4SKZV6YXS3265JMC39NXW</td>\n",
       "      <td>collina strada</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>RUFFLE MARKET DRESS LOOPY PINK SISTINE TOMATO</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-03-09 18:43:10.457 UTC</td>\n",
       "      <td>https://collina-strada-2.myshopify.com/product...</td>\n",
       "      <td>mid length dress with ruffles and adjustable s...</td>\n",
       "      <td>Mid-length dress with ruffles and adjustable s...</td>\n",
       "      <td>ruffle market dress loopy pink sistine tomato</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>one_piece</td>\n",
       "      <td>[PINK]</td>\n",
       "      <td>{pink}</td>\n",
       "      <td>1</td>\n",
       "      <td>pink</td>\n",
       "      <td>collina strada pink ruffle market dress loopy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01EW16A4J6YS4XS4JEWXW3Q46C</td>\n",
       "      <td>misa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>MARION SKIRT</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-14 19:35:14.245 UTC</td>\n",
       "      <td>https://misa-los-angeles.myshopify.com/product...</td>\n",
       "      <td>one of our signature silhouettes is back in a ...</td>\n",
       "      <td>One of our signature silhouettes is back in a ...</td>\n",
       "      <td>marion skirt</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>top</td>\n",
       "      <td>[blue, white, white]</td>\n",
       "      <td>{blue, white}</td>\n",
       "      <td>2</td>\n",
       "      <td>multi</td>\n",
       "      <td>misa multi marion skirt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id           brand brand_category  \\\n",
       "0  01F0C4SKZV6YXS3265JMC39NXW  collina strada        Unknown   \n",
       "1  01EW16A4J6YS4XS4JEWXW3Q46C            misa        Unknown   \n",
       "\n",
       "                                            name details  \\\n",
       "0  RUFFLE MARKET DRESS LOOPY PINK SISTINE TOMATO    None   \n",
       "1                                   MARION SKIRT    None   \n",
       "\n",
       "                    created_at  \\\n",
       "0  2021-03-09 18:43:10.457 UTC   \n",
       "1  2021-01-14 19:35:14.245 UTC   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://collina-strada-2.myshopify.com/product...   \n",
       "1  https://misa-los-angeles.myshopify.com/product...   \n",
       "\n",
       "                                         description  \\\n",
       "0  mid length dress with ruffles and adjustable s...   \n",
       "1  one of our signature silhouettes is back in a ...   \n",
       "\n",
       "                                   brand_description  \\\n",
       "0  Mid-length dress with ruffles and adjustable s...   \n",
       "1  One of our signature silhouettes is back in a ...   \n",
       "\n",
       "                                      brand_name  ...  linen_check  \\\n",
       "0  ruffle market dress loopy pink sistine tomato  ...            0   \n",
       "1                                   marion skirt  ...            0   \n",
       "\n",
       "  bottom_check lingerie_check max_value_cat final_category  \\\n",
       "0            0              0           2.0      one_piece   \n",
       "1            1              0           1.0            top   \n",
       "\n",
       "             color_list         colors n_colors  final_color  \\\n",
       "0                [PINK]         {pink}        1         pink   \n",
       "1  [blue, white, white]  {blue, white}        2        multi   \n",
       "\n",
       "                                   new_brand_product  \n",
       "0  collina strada pink ruffle market dress loopy ...  \n",
       "1                            misa multi marion skirt  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1bcc43",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7686b3",
   "metadata": {},
   "source": [
    "The outfit recommendation system is a function called `outfit( )` \n",
    "- The user enters the search terms into the function as the argument\n",
    "- The function prints a dictionary of the recommended outfit with atleast 3 products in the outfit recommendations\n",
    "\n",
    "> _Our recommendation system is a rule-based algorithm driven by TFIDF and cosine similarity._\n",
    "\n",
    "\n",
    "**The function is comprised of two parts:**\n",
    "- **Part A:** Uses a similarity measure to make recommendations. Part A comprises of three stages:\n",
    "    - **part_A_1** is designed to extract predefined outfits directly from the combinations dataset when the cosine similarity between the query and a product in the **combinations dataset** is greater than  0.5.\n",
    "    - **part_A_2** is designed to deal with queries that fail the 0.5 similarity threshold from part_A_1. This stage then searches the **Behold products dataset** (product) for a product with highest similarity to the query. That product then becomes the \"new search term\" and we aim to return an outfit in the combinations dataset that contains a product that's similar to the \"new search term\". A checkpoint is installed here which is elaborated above the function definition.\n",
    "    - **part_A_3** is designed to process the queries that fail to meet the requirements of both part_A_1 and part_A_2. This stage searches the product dataset for the highest cosine similarity match. We then extract out the brand of this product to create a **brand-based** outfit.\n",
    "    \n",
    "- **Part B:** Designed to deal with edge cases where the user enters a very specific query like \"skirt goes with blue shirt\". In this case, we parse out both the product the user is looking for and the product they want to match it with to return an outfit with maximum similarity.\n",
    "\n",
    "_Note: The reason we chose a sequential process if because we wanted to maximize the chance of returning an outfit curated by a fashion expert._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed14cd4",
   "metadata": {},
   "source": [
    "## Supporting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ace5b",
   "metadata": {},
   "source": [
    "**Part A - Phase 1 (part_a_1)** checks the outfit combinations dataset (combo) and matches the query with the product with the highest similarity score. Since there is a designated outfit for that product in the combo dataset, we simply return all the items with that outfit ID. \n",
    "\n",
    "For this to happen the cosine similarity score must be above **0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c5b82d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:12.270589Z",
     "start_time": "2021-05-12T00:23:12.233359Z"
    }
   },
   "outputs": [],
   "source": [
    "def part_a_1(query):\n",
    "    vectorizer=TfidfVectorizer(ngram_range=(1,1),token_pattern=r'\\b[a-zA-Z]{3,}',stop_words=stopwords)\n",
    "    corpus=list(combo['new_brand_product'].values)\n",
    "    corpus.append(query)\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    terms=vectorizer.get_feature_names()\n",
    "    tf_idf=pd.DataFrame(X.toarray(),columns=terms)\n",
    "    df_sim=pd.DataFrame(cosine_similarity(tf_idf))\n",
    "    # Finding product with maximum similarity\n",
    "    maxvalue=0\n",
    "    length=len(df_sim)\n",
    "    for i in range(length-1):\n",
    "        if df_sim.loc[i,length-1]>maxvalue:\n",
    "            maxvalue=df_sim.loc[i,length-1]\n",
    "            loc_i=i\n",
    "    if maxvalue==0:\n",
    "        rec_dict={}\n",
    "        return rec_dict,maxvalue\n",
    "    # Finding the outfit ID of the product with the highest similarity score\n",
    "    outfits=combo[combo['product_id']==combo.loc[loc_i,'product_id']]['outfit_id']\n",
    "    temp=combo[combo['outfit_id']==list(outfits)[0]][['outfit_item_type','product_full_name','product_id']]\n",
    "    temp['recommendation']=temp['product_full_name'].str.cat(temp['product_id'],sep=' (')+')'\n",
    "    temp.set_index('outfit_item_type',inplace=True)\n",
    "    temp.drop(columns=['product_full_name','product_id'],inplace=True)\n",
    "    rec_dict=temp['recommendation'].to_dict()\n",
    "    # We return both the recommendation and the similarity value\n",
    "    return rec_dict,maxvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf79d304",
   "metadata": {},
   "source": [
    "**Part A - Phase 2 (part_a_2)** \n",
    "\n",
    "If the cosine similarity score from the above step is below 0.5, this phase searches the Behold products dataset (product) for the highest similarity product. That product then becomes the \"new search term\" and we aim to return an outfit in the combo dataset that contains a product that is similar to the \"new search term\". We then install a checkpoint to see if this similarity is greater than 0.5. If it is, this outfit combination is returned, but if it isn't we proceed to the final phase of \"Part A\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "288ee005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:12.314467Z",
     "start_time": "2021-05-12T00:23:12.278717Z"
    }
   },
   "outputs": [],
   "source": [
    "def part_a_2(query):\n",
    "    vectorizer=TfidfVectorizer(ngram_range=(1,1),token_pattern=r'\\b[a-zA-Z]{3,}',stop_words=stopwords)\n",
    "    corpus=list(product['new_brand_product'].values)\n",
    "    corpus.append(query)\n",
    "    corpus=[str(item) for item in corpus]\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    terms=vectorizer.get_feature_names()\n",
    "    tf_idf=pd.DataFrame(X.toarray(),columns=terms)\n",
    "    df_sim=pd.DataFrame(cosine_similarity(tf_idf))\n",
    "    # Finding product with maximum similarity\n",
    "    maxvalue=0\n",
    "    length=len(df_sim)\n",
    "    for i in range(length-1):\n",
    "        if df_sim.loc[i,length-1]>maxvalue:\n",
    "            maxvalue=df_sim.loc[i,length-1]\n",
    "            loc_i=i\n",
    "    # \"item1\" becomes the new search term\n",
    "    item1=product.loc[loc_i,'brand_name']\n",
    "    vectorizer=TfidfVectorizer(ngram_range=(1,1),token_pattern=r'\\b[a-zA-Z]{3,}',stop_words=stopwords)\n",
    "    corpus=list(combo['new_brand_product'].values)\n",
    "    corpus.append(item1)\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    terms=vectorizer.get_feature_names()\n",
    "    tf_idf=pd.DataFrame(X.toarray(),columns=terms)\n",
    "    df_sim=pd.DataFrame(cosine_similarity(tf_idf))\n",
    "    maxvalue=0\n",
    "    length=len(df_sim)\n",
    "    for i in range(length-1):\n",
    "        if df_sim.loc[i,length-1]>maxvalue:\n",
    "            maxvalue=df_sim.loc[i,length-1]\n",
    "            loc_i=i\n",
    "    # Extracting the outfit from the combination dataset based on maximum similarity\n",
    "    outfits=combo[combo['product_id']==combo.loc[loc_i,'product_id']]['outfit_id']\n",
    "    temp=combo[combo['outfit_id']==list(outfits)[0]][['outfit_item_type','product_full_name','product_id']]\n",
    "    temp['recommendation']=temp['product_full_name'].str.cat(temp['product_id'],sep=' (')+')'\n",
    "    temp.set_index('outfit_item_type',inplace=True)\n",
    "    temp.drop(columns=['product_full_name','product_id'],inplace=True)\n",
    "    rec_dict=temp['recommendation'].to_dict()\n",
    "    # We return both the recommendation and the similarity value\n",
    "    return rec_dict,maxvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc2e44",
   "metadata": {},
   "source": [
    "**Part A - Phase 3 (part_a_3)** searches the product dataset for the highest cosine similarity match. We then extract out the brand of this product to create a **brand-based** outfit. \n",
    "\n",
    "The next step in this process is to return an outfit including a top, a bottom, an accessory, and a shoe from the extracted brand. However, if the category of product with the highest cosine similarity match is a \"one_piece\", we only return an accessory and a shoe (The reason is because it wouldn't make sense to include a top and a bottom with this curated outfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5f3e3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:12.392300Z",
     "start_time": "2021-05-12T00:23:12.323360Z"
    }
   },
   "outputs": [],
   "source": [
    "def part_a_3(query):\n",
    "    vectorizer=TfidfVectorizer(ngram_range=(1,1),token_pattern=r'\\b[a-zA-Z]{3,}',stop_words=stopwords)\n",
    "    # Potential components of an outfit\n",
    "    keyList=['top','bottom','acc','shoe','one_piece']\n",
    "    product1=product[product['final_category'].isin(keyList)].reset_index(drop=True)\n",
    "    df=product1.groupby('brand')['final_category'].nunique()\n",
    "    filt=list(df[df>4].index)\n",
    "    product1=product1[product1['brand'].isin(filt)].reset_index(drop=True)\n",
    "    corpus=list(product1['new_brand_product'].values)\n",
    "    corpus.append(query)\n",
    "    corpus=[str(item) for item in corpus]\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    terms=vectorizer.get_feature_names()\n",
    "    tf_idf=pd.DataFrame(X.toarray(),columns=terms)\n",
    "    df_sim=pd.DataFrame(cosine_similarity(tf_idf))\n",
    "    maxvalue=0\n",
    "    length=len(df_sim)\n",
    "    for i in range(length-1):\n",
    "        if df_sim.loc[i,length-1]>maxvalue:\n",
    "            maxvalue=df_sim.loc[i,length-1]\n",
    "            loc_i=i\n",
    "    if maxvalue==0:\n",
    "        maxvalue=0\n",
    "        rec_dict={}\n",
    "        return rec_dict,maxvalue\n",
    "    # Extracting out the category and brand\n",
    "    orig_cat=product1.loc[loc_i,'final_category']\n",
    "    orig_prod=product1.loc[loc_i,'brand_name']\n",
    "    new_brand=product1.loc[loc_i,'brand']\n",
    "    # This path will give a \"one_piece\", \"shoe\", and \"acc\"\n",
    "    if orig_cat=='one_piece':\n",
    "        keyList=['acc','shoe']\n",
    "        rec_dict={}\n",
    "        for i in keyList:\n",
    "            rec_dict[i]=None\n",
    "        for i in keyList:\n",
    "            if len(product1[(product1['brand']==new_brand) & (product1['final_category']==i)].reset_index(drop=True))>0:\n",
    "                temp=product1[(product1['brand']==new_brand) & (product1['final_category']==i)].reset_index(drop=True)\n",
    "                val=temp.loc[0,'brand_name']+' ('+temp.loc[0,'product_id']+')'\n",
    "                rec_dict[i]=val\n",
    "        rec_dict[orig_cat]=orig_prod+' ('+product1.loc[loc_i,'product_id']+')'\n",
    "        maxvalue='Not Applicable'\n",
    "        print('Brand:',new_brand)\n",
    "        return rec_dict,maxvalue\n",
    "    # This path will give a \"top\", \"bottom\", \"shoe\", and \"acc\"\n",
    "    else:\n",
    "        keyList=['top','bottom','acc','shoe']\n",
    "        rec_dict={}\n",
    "        for i in keyList:\n",
    "            rec_dict[i]=None\n",
    "        for i in keyList:\n",
    "            if len(product1[(product1['brand']==new_brand) & (product1['final_category']==i)].reset_index(drop=True))>0:\n",
    "                temp=product1[(product1['brand']==new_brand) & (product1['final_category']==i)].reset_index(drop=True)\n",
    "                val=temp.loc[0,'brand_name']+' ('+temp.loc[0,'product_id']+')'\n",
    "                rec_dict[i]=val\n",
    "        rec_dict[orig_cat]=orig_prod+' ('+product1.loc[loc_i,'product_id']+')'\n",
    "        maxvalue='Not Applicable'\n",
    "        print('Brand:',new_brand)\n",
    "        return rec_dict,maxvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aacef1",
   "metadata": {},
   "source": [
    "**Part B (part_b)** was created to handle edge cases where the user enters in something very specific. For example, we parse out the following statements: \"goes well with\", \"goes with\", \"allows for\", \"pairs well with\", and \"pairs with\". The function captures what's before and after the phrase (`query_a` and `query_b`). These queries are independently utilized to return the highest similarity product from the product dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca9741ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:12.588982Z",
     "start_time": "2021-05-12T00:23:12.410632Z"
    }
   },
   "outputs": [],
   "source": [
    "def part_b(query):\n",
    "    # matching product user mentions in query\n",
    "    query_1=re.findall(r'goes well with ([\\w @;\\n\\.,]+)',query)\n",
    "    query_2=re.findall(r'goes with ([\\w @;\\n\\.,]+)',query)\n",
    "    query_3=re.findall(r'allows for ([\\w @;\\n\\.,]+)',query)\n",
    "    query_4=re.findall(r'pairs well with ([\\w @;\\n\\.,]+)',query)\n",
    "    query_5=re.findall(r'pairs with ([\\w @;\\n\\.,]+)',query)\n",
    "    # Actual product user is searching for\n",
    "    query_a2=re.findall(r'([\\w @;\\n\\.,]+) goes well with',query)\n",
    "    query_b2=re.findall(r'([\\w @;\\n\\.,]+)goes with',query)\n",
    "    query_c2=re.findall(r'([\\w @;\\n\\.,]+)allows for',query)\n",
    "    query_d2=re.findall(r'([\\w @;\\n\\.,]+)pairs well with',query)\n",
    "    query_e2=re.findall(r'([\\w @;\\n\\.,]+)pairs with',query)\n",
    "    for i in [query_1,query_2,query_3,query_4,query_5]:\n",
    "        if len(i)==1:\n",
    "            query1=i\n",
    "    for i in [query_a2,query_b2,query_c2,query_d2,query_e2]:\n",
    "        if len(i)==1:\n",
    "            query2=i\n",
    "    querya=query1[0]\n",
    "    queryb=query2[0]\n",
    "    vectorizer=TfidfVectorizer(ngram_range=(1,1),token_pattern=r'\\b[a-zA-Z]{3,}',stop_words=stopwords)\n",
    "    corpus1=list(product['new_brand_product'].values)\n",
    "    corpus1=[str(item) for item in corpus1]\n",
    "    corpus1.append(querya)\n",
    "    X=vectorizer.fit_transform(corpus1)\n",
    "    terms=vectorizer.get_feature_names()\n",
    "    tf_idf=pd.DataFrame(X.toarray(),columns=terms)\n",
    "    df_sim=pd.DataFrame(cosine_similarity(tf_idf))\n",
    "    maxvalue=0\n",
    "    length=len(df_sim)\n",
    "    for i in range(length-1):\n",
    "        if df_sim.loc[i,length-1]>maxvalue:\n",
    "            maxvalue=df_sim.loc[i,length-1]\n",
    "            loc_i=i\n",
    "    if maxvalue==0:\n",
    "        rec_dict={}\n",
    "        return rec_dict,maxvalue\n",
    "    rec_dict={}\n",
    "    column1=product.loc[loc_i,'final_category']\n",
    "    rec_dict[column1]=product.loc[loc_i,'brand_name']+' ('+product.loc[loc_i,'product_id']+')'\n",
    "    filter1=list(rec_dict.keys())\n",
    "    temp=product[product['final_category'].isin(filter1)==False]\n",
    "    temp.reset_index(drop=True,inplace=True)\n",
    "    vectorizer=TfidfVectorizer(ngram_range=(1,1),token_pattern=r'\\b[a-zA-Z]{3,}',stop_words=stopwords)\n",
    "    corpus2=list(temp['new_brand_product'].values)\n",
    "    corpus2=[str(item) for item in corpus2]\n",
    "    corpus2.append(queryb)\n",
    "    X=vectorizer.fit_transform(corpus2)\n",
    "    terms=vectorizer.get_feature_names()\n",
    "    tf_idf=pd.DataFrame(X.toarray(),columns=terms)\n",
    "    df_sim=pd.DataFrame(cosine_similarity(tf_idf))\n",
    "    maxvalue=0\n",
    "    length=len(df_sim)\n",
    "    for j in range(length-1):\n",
    "        if df_sim.loc[j,length-1]>maxvalue:\n",
    "            maxvalue=df_sim.loc[j,length-1]\n",
    "            loc_j=j\n",
    "    if maxvalue==0:\n",
    "        rec_dict={}\n",
    "        return rec_dict,maxvalue\n",
    "    column2=temp.loc[loc_j,'final_category']\n",
    "    rec_dict[column2]=temp.loc[loc_j,'brand_name']+' ('+temp.loc[loc_j,'product_id']+')'\n",
    "    maxvalue='Not Applicable'\n",
    "    return rec_dict,maxvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec800d3",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227ef4f",
   "metadata": {},
   "source": [
    "This final recommender function called `outfit( )` is what will provide the final outfit recommendation. This function uses the cleaned product and combo dataset and the supporting functions declared above. \n",
    "\n",
    "_Please run the entire notebook once and then the function will be ready to use._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e01645b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:12.631472Z",
     "start_time": "2021-05-12T00:23:12.601311Z"
    }
   },
   "outputs": [],
   "source": [
    "def outfit(query):\n",
    "    query=query.lower()\n",
    "    query_1=re.findall(r'goes well with ([\\w @;\\n\\.,]+)',query)\n",
    "    query_2=re.findall(r'goes with ([\\w @;\\n\\.,]+)',query)\n",
    "    query_3=re.findall(r'allows for ([\\w @;\\n\\.,]+)',query)\n",
    "    query_4=re.findall(r'pairs well with ([\\w @;\\n\\.,]+)',query)\n",
    "    query_5=re.findall(r'pairs with ([\\w @;\\n\\.,]+)',query)\n",
    "    # Makes sure we don't need to utilize \"part_b\"\n",
    "    if (len(query_1)==0) & (len(query_2)==0) & (len(query_3)==0) & (len(query_4)==0) & (len(query_5)==0):\n",
    "        # Function call to \"part_a_1\"\n",
    "        rec_dict,maxvalue=part_a_1(query)\n",
    "        if maxvalue==0:\n",
    "            rec_dict={}\n",
    "            return print(rec_dict)\n",
    "        # Threshold set at 0.5, goes to \"part_a_2\" if not met\n",
    "        if maxvalue<0.5:\n",
    "            rec_dict,maxvalue=part_a_2(query)\n",
    "            # Threshold set at 0.5, goes to \"part_a_3\" if not met\n",
    "            if maxvalue<0.5:\n",
    "                rec_dict,maxvalue=part_a_3(query)\n",
    "                if maxvalue==0:\n",
    "                    rec_dict={}\n",
    "                    return print(rec_dict)\n",
    "    else:\n",
    "        # Deals with our edge cases\n",
    "        rec_dict,maxvalue=part_b(query)\n",
    "        if maxvalue==0:\n",
    "            rec_dict={}\n",
    "            return print(rec_dict)\n",
    "    [print(key,':',value) for key, value in rec_dict.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02230a",
   "metadata": {},
   "source": [
    "## Example Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09c5e38e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:23:16.430573Z",
     "start_time": "2021-05-12T00:23:12.652841Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottom : slim knit skirt (01DMBRYVA2P5H24WK0HTK4R0A1)\n",
      "top : rib mock neck tank (01DMBRYVA2PEPWFTT7RMP5AA1T)\n",
      "accessory1 : medium margaux leather satchel (01DMBRYVA2S5T9W793F4CY41HE)\n",
      "shoe : penelope mid cap toe pump (01DMBRYVA2ZFDYRYY5TRQZJTBD)\n"
     ]
    }
   ],
   "source": [
    "# Eileen Fisher is a brand \n",
    "outfit('eileen fisher slim knit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "045a4cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:24:34.618549Z",
     "start_time": "2021-05-12T00:23:16.462095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top : pj shirt in black (01EP63JYKXXTFQKMKNN3RNNVDS)\n",
      "bottom : b(air) ankle skinny jeans (01E6070892T9HB6NZ6APHTZ70N)\n"
     ]
    }
   ],
   "source": [
    "# Both phrases need to be valid to return a match\n",
    "outfit('skinny jeans goes well with black shirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "054b3262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:25:47.163402Z",
     "start_time": "2021-05-12T00:24:34.644097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand: 6397\n",
      "top : lori shirt in blue (01F39R5Q9H6YBSEDE1NAAN7XWM)\n",
      "bottom : pull-on trouser in navy (01EP63R8A0KE3MZ819N5C4T3G1)\n",
      "acc : grey plaid summer v-neck shirtdress (01ESCC0YDWYFRYMHVEP4YWBNT9)\n",
      "shoe : 6397 clogs in blue denim (01EP62NW4TV1ND02A2EHMJTM4H)\n"
     ]
    }
   ],
   "source": [
    "# Prints the phases the query travels through\n",
    "outfit('blue shirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30399378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:28:33.481093Z",
     "start_time": "2021-05-12T00:27:16.385421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand: chufy\n",
      "acc : talisman harmony earrings (01EEZT37R6FZFKA4MGZKQQRHKY)\n",
      "shoe : aroa nappa' black sandals (01ED4MVFN5XYJZZXH0ECTZ40FY)\n",
      "one_piece : re red mini dress (01EKJJ5D9SBBT68RRP30TYT2PK)\n"
     ]
    }
   ],
   "source": [
    "outfit('red dress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fab60b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:28:35.629233Z",
     "start_time": "2021-05-12T00:28:33.487800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottom : dazzler distressed slim ankle jeans (01DT0DHSDTQ34YYDQZ856T6WP9)\n",
      "accessory2 : you're cute classic cotton tee (01DT0DJMGB47PSW7H695CJHXNT)\n",
      "accessory1 : mia printed leather shoulder bag (01DT8NCT6C6734WAWTYZX94SE8)\n",
      "top : checked wool shirt (01DVCT2ANYEJBJ8EKD8XJCBB7P)\n",
      "shoe : cabria leather ankle boots (01DVCTFR5MA1ZDKTAFS4VG4VW4)\n"
     ]
    }
   ],
   "source": [
    "outfit('shirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0b709cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:29:25.863346Z",
     "start_time": "2021-05-12T00:28:35.664312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Both phrases need to be valid to return a match\n",
    "outfit('skinny jeans goes well with xxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5b9b3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:29:27.904949Z",
     "start_time": "2021-05-12T00:29:25.869544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Returns an empty dictionary when given a poor request\n",
    "outfit('abc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb313f",
   "metadata": {},
   "source": [
    "# For Exploration Purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b4b86a",
   "metadata": {},
   "source": [
    "We explored fuzzy matching and Doc2Vec in conjunction with cosine similarity. We ultimately decided to go with TFIDF and cosine similarity, but we still wanted to provide simple examples of each for context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1293e8",
   "metadata": {},
   "source": [
    "## Option 1: Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0e9b4e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:29:29.080917Z",
     "start_time": "2021-05-12T00:29:27.912535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bottom': 'slim knit skirt (01DMBRYVA2P5H24WK0HTK4R0A1)',\n",
       " 'top': 'rib mock neck tank (01DMBRYVA2PEPWFTT7RMP5AA1T)',\n",
       " 'accessory1': 'medium margaux leather satchel (01DMBRYVA2S5T9W793F4CY41HE)',\n",
       " 'shoe': 'penelope mid cap toe pump (01DMBRYVA2ZFDYRYY5TRQZJTBD)'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q='Rib Mock Neck Tank'\n",
    "max_sim=0\n",
    "for i in combo.index:\n",
    "    if fuzz.token_set_ratio(combo.loc[i,'product_full_name'],q)>max_sim:\n",
    "        res_i=i\n",
    "        max_sim=fuzz.token_set_ratio(combo.loc[i,'product_full_name'],q)\n",
    "outfits=combo[combo['product_id']==combo.loc[res_i,'product_id']]['outfit_id']\n",
    "temp=combo[combo['outfit_id']==list(outfits)[0]][['outfit_item_type','product_full_name','product_id']]\n",
    "temp['recommendation']=temp['product_full_name'].str.cat(temp['product_id'], sep=' (')+')'\n",
    "temp.set_index('outfit_item_type',inplace=True)\n",
    "temp.drop(columns=['product_full_name','product_id'],inplace=True)\n",
    "rec_dict=temp['recommendation'].to_dict()\n",
    "rec_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668913a",
   "metadata": {},
   "source": [
    "## Option 2: Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "316d4d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:29:42.943862Z",
     "start_time": "2021-05-12T00:29:29.088898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accessory1': 'lilleth metal cage clutch (01DT0DJSS1Y0SYS1G2H13CC3Y5)',\n",
       " 'accessory2': 'jane silk-satin camisole (01DT512VDZ03SMBTPNCRYPXZZX)',\n",
       " 'bottom': 'manu cropped leather wide-leg pants (01DT517935D6N4Z2G1HFB4DT2A)',\n",
       " 'top': 'tiger-print lurex cardigan (01DVP7RVX271PQ54TKKWQ8DGYD)',\n",
       " 'shoe': 'tanya metallic leather mules (01DVP8HWCYG3AP0Z0ZJFVME4W7)'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q='leather satchel'\n",
    "documents=[TaggedDocument(doc, [i]) for i, doc in enumerate(combo['product_full_name'])]\n",
    "model=Doc2Vec(documents)\n",
    "new_q=model.infer_vector([q]).reshape(1,-1)\n",
    "max_d2v=0\n",
    "for i in combo.index:\n",
    "    doc_vec=model.infer_vector([combo.loc[i,'product_full_name']]).reshape(1,-1)\n",
    "    if cosine_similarity(doc_vec,new_q)>max_d2v:\n",
    "        res_i=i\n",
    "        max_d2v=cosine_similarity(doc_vec,new_q)\n",
    "outfits=combo[combo['product_id']==combo.loc[res_i,'product_id']]['outfit_id']\n",
    "temp=combo[combo['outfit_id']==list(outfits)[0]][['outfit_item_type','product_full_name','product_id']]\n",
    "temp['recommendation']=temp['product_full_name'].str.cat(temp['product_id'], sep=' (')+')'\n",
    "temp.set_index('outfit_item_type',inplace=True)\n",
    "temp.drop(columns=['product_full_name','product_id'],inplace=True)\n",
    "rec_dict=temp['recommendation'].to_dict()\n",
    "rec_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e263a7e",
   "metadata": {},
   "source": [
    "## Future Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d618b3",
   "metadata": {},
   "source": [
    "- If given unlimited resources, we would have liked to explore the potential of \"Knowledge Graphs\". Based on our research, this is a large undertaking that requires many hours of devotion to implement.\n",
    "\n",
    "\n",
    "- We also would like to further research the feasibility of using weighted TF-IDF document vectors. We tried doing this but it blew up the dimensionality. To reduce dimensionality, we explored using SVD or PCA but the cosine similarity was adversely affected. We did, however, utilize more than one column of information when constructing our TF-IDF corpus.\n",
    "\n",
    "\n",
    "- Another method we considered for our recommendations was to weigh the product by the brand instead of concatenating columns. We calculated the similarity separately and then combined the similarity from brand_name and brand_description, giving 80% weightage to description and 20% to brand_name. Using this technique, we got better similarity scores but the recommendations were less intuitive. We were not sure why since it seems counter-intuitive to have higher similarity but worse recommendations. Our suspicion is that by assigning weights to brand name, other products from the same brand become more similar which end up taking the recommendation in a different direction than the actual product. We were unable to confirm this suspicion and given more time could have explored this further. Within the scope of this project, we decided to go ahead with the concatenation logic.\n",
    "\n",
    "```python\n",
    "    # weighing by brand name\n",
    "    weight_corpus=list(product['brand_name'].values)\n",
    "    weight_corpus=[str(item) for item in weight_corpus]\n",
    "    weights=vectorizer.fit_transform(weight_corpus)\n",
    "    weight_df=pd.DataFrame(weights.toarray())\n",
    "    df_sim_brand=pd.DataFrame(cosine_similarity(tf_idf)).fillna(10^(-10))\n",
    "    \n",
    "    # Description gets a weight of .8 and brand name gets a weight of .2\n",
    "    df_sim=0.8*df_sim_desc+0.2*df_sim_brand\n",
    "```\n",
    "\n",
    "- In addition, we also would like to increase our scope to design an outfit when a user enters in a brand name and nothing else."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
